\newpage
# Capítulo 09: Main Memory

* Each memory-management approach highly dependent on the hardware.

## 9.1 Classic Problems of Synchronization
* Memory consists of a large array of bytes, each with its own address.
* The CPU fetches instructions according to the value in the Program Counter.

### 9.1.1 Basic Hardware
* Main memory and registers are the only general-purpose storage that the CPU can access directly.
    * No instructions take disk addresses as arguments.
    * All processes must be moved to the main memory in order to start execution.
* Registers built in the CPU core are usually accessable in 1 clock cycle.
    * The same cannot be said for main memory.
    * To access the main memory, the _memory bus_ must be used, and it can take several clock cycles to finish, generating a **stall**.
* To increase this process, a **cache** is used.
* **Protection**:
    * We must protect OS's by user processes access, as well user processes from others.
    * This protection is implemented in **hardware level**:
        * OS doesn't usually intervene between CPU and its memory, due to the performance penalty.
    * **1.** Each process must hava separate memory space.
    * **2.** We can provide this protection using two registers:
        * **Base register**: holds the smallest legal physical memory address
        * **Limit register**: holds the size of the range.
![ProcessSeparation](img/cap09/01_process_separation_base_limit.png "A base and a limit register define a logical address space.")
* Protection of memory space is accomplished by having the CPU hardware compare every address generated in user mode with the registers. 
* Any attempt by a program executing in user mode to access operating-system memory or other users’ memory results in a trap to the operating system, which treats the attempt as a fatal error. 
* This scheme prevents a user program from modifying the code or data structures of either the operating system or other users.
* The base and limit registers can only be loaded by the OS.
### 9.1.2 Address Binding
* Most systems allow a process to reside in any part of the physical memory.
* Addresses in the source program are usually symbolic, and the compiler binds them to relocatable absolute addresses.
* The binding of instructions and data memory can be done in each step:
    * **Compile time**: if you know at compiling time where the process will reside, then **absolute code** can be generated. To change this position, the program must be recompiled.
    * **Load time**: if you _don't_ know at compiling time where the process will reside, the compiler must generate a **relocatable code**, and final biding is delayed until load time.
    * **Execution time**: if the process can be moving during execution, final biding is delayed until run time. Special hardware is needed. Most OSs uses this method.
### 9.1.3 Logical vs Physical Address Space
* **Logical address**: generated by the CPU
* **Physical address**: seen by the memory unit - the one loaded into the **memory-address register**.
* Binding addresses at either compile or load time generates identical logical and physical addresses. That's not true for execution time bidings (**virtual address**).
* The run-time mapping is done by the **memory-management unit (MMU)**:
    * **Relocation register**: like the base register; its value is added to every generated address.
* **The user processes never deal with the real physical addresses.**
### 9.1.4 Dynamic Loading
* **Dynamic loading**: a routine is not loaded util it is called.
    * All routines are kept on disk in a relocatable load format. 
    * The main program is loaded into memory and is executed. 
    * When a routine needs to call another routine, the calling routine first checks to see whether the other routine has been loaded. 
    * If it has not, the relocatable linking loader is called to load the desired routine into memory and to update the program’s address tables to reflect this change. 
    * Then control is passed to the newly loaded routine.
* It is particularly useful when large amounts of code are needed.
* It does not require special support from the OS; it is user's responsibility to design their programs to take advantage of this.
### 9.1.4 Dynamic Linking and Shared Libraries 
* **Dynamic Linked Libraries (DLL)** are system libraries that are linked to user programs when the programs are run.
* Some OSs support only **static linking**, while others support **dynamic linking**.
* **Dynamic linking** are similar to dynamic loading, but linking, instead of loading is postponed until execution time.
* This feature is usually used with system libraries, such as C libraries.
* DLLs are also known as **shared libraries**, and are used extensively in Linux and Windows.
* DLLs can be extended to library updates.

## 9.2 Contigous Memory Allocation
* The memory is usually divided in two partitions: one for user's applications, other for OS.
* The OS can be placed in both lower or higher memory addresses; many operating systems (including Linux and Windows) uses higher addresses for the OS.
* We need to consider how to allocate available memory to the processes that are waiting to be brought to memory.
* **Contigous allocation**:
    * each process is contained in a single section of memory that is contigous to the section containing the next process.
### 9.2.1 Memory Protection 
* We can prevent a process from accessing memory that it does not own using a **relocation register** and a **limit register**.
* When the CPU scheduler selects a process for execution, the dispatcher loads the relocation and limit registers with the correct values as part of the context switch.
* Because every address generated by a CPU is checked against these registers, we can protect both the operating system and the other users’ programs and data from being modified by this running process.
* The relocation-register scheme provides an efficient way for the OS to change its size dynamically.
![ProcessSeparation](img/cap09/02_hardware_for_relocation_and_limit.png "Hardware support for relocation and limit registers.")
### 9.2.2 Memory Allocation
* One of the simplest methods for memory alocation is to assign processes to variably sized partitions in memory, each one containing exactly one process.
* In this **variable-partition scheme**, the OS keeps a table containing all available regions and all that are occupied.
* What if there isn't sufficient space?
    * One option is to simply reject the process.
    * Or we can put it into a wating queue.
* **Dynamic storage-allocation problem**: how to satisfy a request of size _n_ from a list of free holes. There are many solutions:
    * **first-fit**:
        * allocate the first hole that is big enough. 
        * we can stop searching as soon as we find a fit.
    * **best-fit**
        * allocate the smallest hole that is big enough. 
        * we must search the entire list. 
        * produces the smallest leftover.
    * **worst-fit**
        * allocate the largest hole
        * we must search the entire list. 
        * produces the largest leftover (which may be more useful).
* Both first fit and best fit are better than worst fit in terms of decreasing time and storage utilization.
* Neither first fit nor best fit is clearly better than the other in terms of storage utilization, but **first fit is generally faster**.
### 9.2.3 Fragmentation
* Both first-fit and best-fit suffer from **external fragmentation**.
* There is no clear winner; each one of them is best for different systems.
* **50-percent rule**: given _N_ allocated blocks, 0.5 _N_ will be lost due to fragmentation.
* **Internal fragmentation**:
    * Example: 
        * we have 18466 bytes, we allocate 18464 of them, lefting 2 bytes.
        * the overhead to keep track of this is larger than the partition itself.
    * The general approach to avoid this is to **break the physical memory into fixed-sized blocks.**
* One solution to _external fragmentation_ is **compaction**, which consists in placing all free memory in one huge block.
    * It is **not** always possible to execute compatction.
        * It is possible only if relocation is dynamic and is done in execution time.
    * Simplest algorithm: move all processes towards one end. **It can be expensive**.
    * Another solution is to permit the logical address space of processes to be noncontigous, thus allowing a process to be allocated physical memory wherever such memory is available.
    * Such strategy is used in **paging**, the most common memory-management techinique.

## 9.3 Fragmentation
